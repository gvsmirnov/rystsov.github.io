---
layout: post
title: rystsov::How Paxos works
name: How Paxos works
tags: ["tbd"]
desc: "A memo on how Paxos works"
has_comments: true
has_math: true
ignore_css: true
marker: hpw
---

<div class="abstract">
	<h1>A memo on how Paxos works</h1>
	<p>
		<span class="label">Abstract.</span>
		<span class="text">Once I understood Paxos but a couple of months later I realised that I didn't. I reread 'Paxos Made Simple' but it was almost as hard as the first time so I wrote this memo to help me in the future to understand Paxos faster.</span>
	</p>
</div>

<div id="overview1" class="brim"><div class="content">
	<h2>Overview</h2>
</div></div>

<div class="brim"><div class="content">
	<p class="edge">Paxos is a class of synod-based algorithms for building available consistent distributed systems on top of asynchronous and unreliable network. For example if you're building a key/value storage then Paxos will help you to keep it working in the present of network errors (partition-tolerance), node failures (availability) and to produce non-contradictory (between clients) views.</p>
	
	<blockquote>&gt; Doesn't it violate CAP theorem?</blockquote>
		
		<p>No, it doesn't. Availability in the CAP sense is very strict. For example, a system using two-phase commit (2PC) algorithm and a system using Paxos algorithm are both unavailable in a CAP sense. It makes sense for the 2PC system since the 2PC's coordinator is a single point of failure but it's strange for Paxos because it tolerates up to N fails out of 2N+1 nodes.</p>

		<p>Paxos is an available in common sense CP system.</p>
	
	<blockquote>&gt; What can we build with Paxos?</blockquote>
		
		<img src="{{ site.url }}/images/put-on-paxos.jpg" width="500"/>

		<p>We can build a distributed state machine with Paxos and implement any algorithm on top of it. But it's very hard to think about an unscoped domain, so in this post we consider Paxos as a foundation for building distributed data storages.</p>

		<p>It's a common practice for storages to have write operations to mutate its state and read operations to query it. Paxos is different, it guaranties consistency only for write operations, so to query its state the system makes read, writes the state back and when the state change is accepted the system queries the written state.</p>

	<blockquote>&gt; Wait, don't pay so much attention to the details, what is the topology of the Paxos-based distributed system?</blockquote>

		<p>Usually a Paxos-based distributed system consists of clients, proposers and acceptors. Clients mutate and query the state of the system, proposers process the client's commands and acceptors store the information.</p>

		<p>The paxos topology is similar to the typical 3-tier application (where clients are web-browsers, proposers are front-end servers and acceptors are databases).</p>

	<blockquote>&gt; If proposals are similar to front-end servers does it mean that the proposals are stateless?</blockquote>

		<p>No, proposals should be able to generate a global unique ID (ballot number) for every request it process. They store last used ballot number to be able to generate a new one which is greater than the current. For example servers may have unique coprime numbers as ID and generate next ballot number as a next number which is divisible by the current node's ID and coprime with the ID of the other nodes. If the id of two servers are 3 and 5 then two sequences they generate are 3,6,9,12,18,.. and 5,10,20,25,35,..</p>

	<blockquote>&gt; Ok, how proposal and acceptors communicate to agree on the system state?</blockquote>

		<p>Let's take a look on how a Paxos-based distributed system handles a state mutation request. In typical case is:</p>

		<ol>
			<li>Client connects to any single proposal and issue the command.</li>
			<li>The proposal commnicates with the acceptors and agree on the system's state.</li>
			<li>Once the change is accepted all reads should reflect the change.</li>
		</ol>

		<img src="{{ site.url }}/images/paxos-seq.png" width="600"/>

		<p>On the diagram we see two rounds of proposal-acceptors communications. We also can estimate that the system generates from <code>4f+6</code> to <code>8f+6</code> messages for every change/read where <code>f</code> is a number of failures that the system can tolerate.</p>

		<p>If something bad happens and client doesn't recieve a confirmation then she should query the system to understand if her change was applied or not. For example it may happen when the concurrent requests from the clients may collide and abort each other.</p>
</div></div>

<div id="code1" class="brim"><div class="content">
	<h2>Code</h2>
</div></div>

<div class="brim"><div class="content">
	<p class="edge">Ok. Let's start with the acceptors. As you can see from the sequence diagram it supports two phases: prepare and accept. They are supported via the corresponding endpoints. The algorithm itself is written in a Python inspired pseudocode. I assume that every hdd.write call is flushed to the disk.</p>

		{% gist rystsov/44b25528e74bb617726d %}

		<p>As you remember clients communicate only with the proposals so it's a good idea to explore its API. I did mention before that Paxos guarantees consistensy only for write requests so it shouldn't be a surprise that the proposer's API consists just of one <code>change_query</code> endpoint.</p>

		<p>It accepts two pure function: <code>change</code> and <code>query</code>. The <code>change</code> function validates the old state and maps it into the new state (or throws an exception). The <code>query</code> function makes a projection of the new state and returns it to the client.</p>

		<p>Consider that we want to read a distributed variable then we may use identity transform both as <code>change</code> and as <code>query</code>. If we want to perfom a CAS-guarded state transition from old to new value then we should use the following change-generator:</p>

		{% gist rystsov/1517327d88eb3576ef94 %}

		<p>Once we digest all the previous information the proposal's source code shouldn't be too scary.</p>

		{% gist rystsov/ca9d195b2737039faaf3 %}
</div></div>

<div id="math1" class="brim"><div class="content">
	<h2>Math</h2>
</div></div>

<div class="brim"><div class="content">
	<p class="edge">The Paxos algorithm gives us a way to build reliable distributed data structures which keep work in a predictable way even if the whole system experiences network partitioning or node failures. As long as a client can communicate with a proposer and the proposer sees the quorum of the acceptors then the distributed storage behaves like a thread safe data structure. Otherwise the system is unavailable.</p>
</div></div>


<div class="brim alt defs1"><div class="content">
	<p class="edge">Let's prove it. As you can see from the sources the system generates events of different kind (emit_executed, emit_prepared, emit_accepted and emit_promised). We will show that:</p>

		<ol>
			<li>there is a relation between emit_accepted events which captures casuality between them</li>
			<li>the relation is also defined on emit_executed</li>
			<li>the reduction of the relation on emit_executed is total order</li>
		</ol>

		<p>The 3rd bullet means that any successful change is an effect of the previously successful change.</p>

		<p>We should introduce a couple of contractions for the events name to simplify the reasoning about the space of events.</p>

		<table>
		    <tr><th>In the code</th><th>In the proof</th></tr>
                    <tr><td>emit_executed(n,...)</td><td class="abbr">$\bar{n}^2$</td></tr>
		    <tr><td>emit_prepared(n,...)</td><td class="abbr">$\bar{n}^1$</td></tr>
		    <tr><td>emit_accepted(n,...)</td><td class="abbr">$\ddot{n}^2$</td></tr>
		    <tr><td>emit_promised(n,...)</td><td class="abbr">$\ddot{n}^1$</td></tr>
		</table>

		<p>$\bar{n}^1$ and $\bar{n}^2$ are single events, but $\ddot{n}^1$ and $\ddot{n}^2$ each is a set of events where different events corespond to different acceptors.</p>

		<p>By the definition:</p>

		$$ \forall \ddot{b}^2 \in \mathrm{E} \quad \exists \ddot{a}^2 \in \mathrm{E} \,:\, \mathrm{s}(\ddot{b}^2) = \mathrm{change}(\mathrm{s}(\ddot{a}^2))$$

		<p>where <span class="imb">$\mathrm{E}$</span> is a space of events generated by the system and <span class="imb">$\mathrm{s}(x) := x.\mathrm{state}$</span>. In such cases we say that $\ddot{a}^2$ is an ancestor of $\ddot{b}^2$ and we use the subset sign to express it: <span class="iml">$\mathrm{s}(\ddot{a}^2) \subset \mathrm{s}(\ddot{b}^2)$</span>.</p>
		
		<p>Let's extend $\subset$ to be transitive: we say that <span class="imb">$\mathrm{s}(\ddot{a}^2) \subset \mathrm{s}(\ddot{c}^2)$</span> if <span class="imb">$\mathrm{s}(\ddot{a}^2) \subset \mathrm{s}(\ddot{b}^2)$</span> and <span class="imb">$\mathrm{s}(\ddot{b}^2) \subset \mathrm{s}(\ddot{c}^2)$</span>. Since casuality is also transitive this extention respects it.</p>

		<p>We want to extend extend the $\subset$ relation on $\bar{x}^2$ events. We say that <span class="imb">$\mathrm{s}(\bar{x}^2) \subset y$</span> if <span class="iml">$\forall \ddot{x}^2 \; \mathrm{s}(\ddot{x}^2) \subset y$</span>. For example</p>
		
		$$\mathrm{s}(\bar{x}^2) \subset \mathrm{s}(\bar{y}^2)$$

		<p>means</p>

		$$\forall \ddot{x}^2 \; \forall \ddot{y}^2 \,:\, \mathrm{s}(\ddot{x}^2) \subset \mathrm{s}(\ddot{y}^2)$$
</div></div>


<div class="brim theorem1"><div class="content theorem">
	<div class="label">Statement.</div>
		<div class="text">
			<p>We're proving that:</p>

			$$\mathrm{s}(\bar{n}^2) \subset \mathrm{s}(\bar{m}^2) \;\vee\; \mathrm{s}(\bar{m}^2) \subset \mathrm{s}(\bar{n}^2)$$

			<p>It obviously holds for any track if the following expression is true for the same track:</p>

			$$n&lt;m \;\Rightarrow\; \mathrm{s}(\bar{n}^2) \subset \mathrm{s}(\bar{m}^2)$$

			<p>Which holds if:</p>

			$$n&lt;m \;\Rightarrow\; \mathrm{s}(\bar{n}^2) \subset \mathrm{s}(\ddot{m}^2)$$

			<p>Let's prove it.</p>
		</div>
	<div class="label">Proof.</div>
		<div class="text">
			<p>First we define <code>unwrap</code> function which maps a ballot number of the write to the ballot number of the previous write.</p>

			$$\mathrm{unwrap}(\ddot{x}^2) := \bar{x}^1.\mathrm{vassals}.\mathrm{max}(x \to x.\mathrm{accepted\_n}).\mathrm{accepted\_n}$$

			<p>We may think about <code>unwrap</code> as an invertion of the <code>change</code>, because</p>

			$$\mathrm{s}(\ddot{b}^2) = \mathrm{change}(\mathrm{s}(\ddot{a}^2)) \;\Rightarrow\; a=\mathrm{unwrap}(\ddot{b}^2)$$

			<p>We also need a couple of lemmas:</p>

			<ol>
				<li>$\mathrm{s}(\ddot{b}^2) = \mathrm{change}(\mathrm{s}(\ddot{a}^2)) \;\Rightarrow\; a&lt;b$</li>
				<li>$\forall \bar{a}^2 \in \mathrm{E} \quad \forall b>a \,:\, \ddot{b}^2 \in \mathrm{E} \;\Rightarrow\; a \leq \mathrm{unwrap}(\ddot{b}^2)$</li>
			</ol>

			<p>We want to prove the following statement:</p>

			$$n&lt;m \;\Rightarrow\; \mathrm{s}(\bar{n}^2) \subset \mathrm{s}(\ddot{m}^2)$$

			<ol>
				<li><span class="im">$k := 0$</span>,<span class="iml">$z := m$</span></li>
				<li>$z_{k+1} := \mathrm{unwrap}(\ddot{z_k}^2),\;k:=k+1$. Lemma 1 guarantees that for any <span class="imb">$y&lt;x$</span> the <span class="im">$\ddot{z_x}^2$</span> is an ansestor of <span class="im">$\ddot{z_y}^2$</span></li>
				<li>Lemma 2 states that $n \leq z_k$. So we have two cases:
					<ol type="i">
						<li>If <span class="imb">$n &lt; z_k$</span> then goto step #2</li>
						<li>If <span class="imb">$n = z_k$</span> then <span class="iml">$\mathrm{s}(\bar{n}^2) \subset \mathrm{s}(\ddot{m}^2)$</span> because $z_k$ is an ansestor of $z_0$ which is $m$</li>
					</ol>
				</li>
			</ol>

			<div class="qed">Q.E.D.</div>
		</div>
</div></div>

<div class="brim alt lemma1"><div class="content theorem">
	<div class="label">Lemma 1.</div>
		<div class="text"><span class="imr">$\mathrm{s}(\ddot{b}^2) = \mathrm{change}(\mathrm{s}(\ddot{a}^2)) \;\Rightarrow\; a&lt;b$</span> is true because we explicitly check it in the proposer's source code, see <a href="https://gist.github.com/rystsov/ca9d195b2737039faaf3#file-how-paxos-proposer-py-L24">the monotonicity assert</a>.</div>
</div></div>

<div class="brim lemma2"><div class="content theorem">
	<div class="label">Lemma 2.</div>
		<div class="text">
			$\forall \bar{a}^2 \in \mathrm{E} \quad \forall b>a \,:\, \ddot{b}^2 \in \mathrm{E} \;\Rightarrow\; a \leq \mathrm{unwrap}(\ddot{b}^2)$
		</div>
	<div class="label">Proof.</div>
		<div class="text">
			<p>Since we don't write a new state $\ddot{b}^2$ unless we got a confirmation from the majority $\bar{b}^1$ then the following statement holds:</p>

			$$\forall \ddot{b}^2 \in \mathrm{E} \;\Rightarrow\; \forall \bar{b}^1 \in \mathrm{E}$$
			
			<p>Proposer should receive promises from a majority of the acceptors before it generates a $\ddot{b}^1$ event. It guarantees truth of the following expression:</p>

			$$\mathrm{N} := \bar{b}.\mathrm{vassals}.[\mathrm{node\_id}] \cap \ddot{a}^2.[\mathrm{node\_id}] \neq \emptyset$$

			<p>where <span class="iml">$\bigtriangleup.[\odot]\equiv\bigtriangleup.\mathrm{map}(x\to x.\odot)$</span>.</p>
			
			<p>Let <span class="iml">$n \in \mathrm{N}$</span>, <span class="imb">$\dot{a}^2 \in \ddot{a}^2 \cap \mathrm{E[n]}$</span> and <span class="imb">$\dot{b}^1 \in \ddot{b}^1 \cap \mathrm{E[n]}$</span> where <span class="imb">$\mathrm{E[n]}$</span> are events that happened on the $n$ node.</p>

			<p><span class="imr">$\dot{a}^2.\mathrm{ts} &lt; \dot{b}^1.\mathrm{ts}$</span> holds because acceptor doesn't accept states with lower ballot number when it promised to accept a state with higher ballot number and <span class="iml">$a&lt;b$</span>.</p>
			
			<p>By definition <span class="imb">$\dot{a}^2.\mathrm{accepted\_n}$</span> is the ballot number of the accepted state at monent <span class="imb">$\dot{a}.\mathrm{ts}$</span> on node $n$. The same is also true for $\dot{b}^1$.</p>

			<p>Since the ballot numbers of the accepted state is a monotonically increasing function of time then</p>

			$$\dot{a}^2.\mathrm{accepted\_n} \;\leq\; \dot{b}^1.\mathrm{accepted\_n}$$

			<p>By definition <span class="imb">$\dot{b}^1.\mathrm{accepted\_n} \in \bar{b}^1.\mathrm{vassals}.[\mathrm{accepted\_n}]$</span> so</p>

			$$\dot{b}^1.\mathrm{accepted\_n} \;\leq\; \bar{b}^1.\mathrm{vassals}.\mathrm{max}(x \to x.\mathrm{accepted\_n}).\mathrm{accepted\_n} \;=\; \mathrm{unwrap}(\ddot{b}^2)$$

			<p>And it's the final in prooving the lemma since:</p>

			$$a \;=\; \dot{a}^2.\mathrm{accepted\_n} \;\leq\; \dot{b}^1.\mathrm{accepted\_n} \;\leq\; \mathrm{unwrap}(\ddot{b}^2)$$

			<div class="qed">Q.E.D.</div>
		</div>
</div></div>

<div id="conclusion1" class="brim"><div class="content">
	<h2>Conclusion</h2>
</div></div>

<div class="brim"><div class="content">
	<p class="edge">The family of Paxos algorithms provides powerful primitives for building robust distributed systems and data structures like distributed switch, distributed variable (a foundation for a hashtable aka key/value storage), distributed log and a generic state machine.</p>
</div></div>

<div class="brim alt examples1"><div class="content">
	<p class="edge">For example we'll define a distributed switch and variable as a simple layer on the algorithm described in this post.</p>

	<h3>Distributed switch</h3>

	{% gist rystsov/0f5f6bcb82b9d666769d %}

	<h3>Distributed variable</h3>

	{% gist rystsov/23ff19e75903f6d87b39 %}
</div></div>

<div class="brim"><div class="content">
	<p class="edge">If you read <a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf">Paxos Made Simple</a> then you migth have noticed that the algorithm in this post is a little bit different. Leslie Lamport described a distributed switch (aka single degree paxos) and shown how to run multiple copies of it to build a distributed state machine.</p>

	<blockquote>&gt; It seems that the "Paxos Made Simple" version is more complex. Is it really true?</blockquote>

	<p>Yes it is, but it doesn't mean that it is worser; it just does more and it is natural to expect that it is more complex. For example Multi-Paxos:</p>

	<ol>
		<li>supports several concurrent state modifications if they don't conflict (see the $\alpha$ parameter)</li>
		<li>keeps the history of previous states</li>
	</ol>

	<blockquote>&gt; Are the Multi-Paxos's extra features important?</blockquote>

	<p>It depends. If we want to build a key/value storage then we can take Multi-Paxos or Raft and put the key/value logic behind it. In theory performance of the storage should be limited by network and disk throughput because the operations with different keys are independent and the algorithm supports concurency. In practice performance of the well known CP systems is low.</p>

	<p>According to the official documents<sup><a href="http://wiki.apache.org/hadoop/ZooKeeper/Performance">[1]</a></sup> performance of the 3-node Zookeeper cluster is close to 20K ops per second. Etcd is another famous CP system and its performance is close to 5K ops per second<sup><a href="https://github.com/coreos/etcd/blob/master/Documentation/benchmarks/etcd-2-2-0-rc-benchmarks.md">[2]</a></sup>.</p>

	<p>However avarage hardware can provide 150Mb/s for HDD, so the expected performance should be close to 200K ops per second.</p>

	<p>It happens because Raft and Multi-Paxos has intristic limitation on thier concurency support. For example when Multi-Paxos inserts a value into the log it should invalidate all previous unknown positions in the log. The number of unknown positions depends on the same $\alpha$ parameter that controls the number of concurrent operations, so it's obvious that the performance as a function of $\alpha$ looks like an upside down parabola and achieves its maximum.</p>

	<p>If we take another approach and run an independent instance of single degree Paxos presented in this post per each key then we can achieve much better performance because we don't coordinate the updates to different keys. This idea aligns both with academia and industry. For example, famous distributed systems researcher Peter Bailis made the <a href="https://www.youtube.com/watch?v=EYJnWttrC9k">Coordination-Avoiding Systems Design</a> talk about the similar idea. Folks behind the CockroachDB <a href="https://github.com/cockroachdb/cockroach/blob/master/docs/design.md">chose an transitional approach</a> for their db: they break the key space into a set of small ranges and run independent Raft implementation per each range.</p>

	<p>So Multi-Paxos and Raft have advantage over single degree Paxos state machine, but for some applications (like key/value storages) those advantage are irrelevant and introduce redundant complexity.</p>
</div></div>
